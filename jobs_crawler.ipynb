{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f2c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random, re, urllib.parse\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from getpass import getpass\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d6fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 设置工作路径为当前notebook所在目录\n",
    "notebook_dir = os.getcwd()\n",
    "if notebook_dir not in sys.path:\n",
    "    sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee34e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler import linkedin_common_crawler, login_linkedin\n",
    "from url_generator import generate_urls\n",
    "from cookies import save_cookies, load_cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda0b025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 270 combinations...\n",
      "Successfully generated 270 URLs.\n"
     ]
    }
   ],
   "source": [
    "urls = generate_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206d07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pool: 10\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "max_workers = 10\n",
    "executor = ThreadPoolExecutor(max_workers=max_workers)\n",
    "\n",
    "print(f\"Max Pool: {max_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0863ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already added 270 URLs in the queue.\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# 创建一个队列并将urls加入队列\n",
    "url_queue = Queue()\n",
    "for url in urls:\n",
    "    url_queue.put(url)\n",
    "\n",
    "print(f\"Already added {url_queue.qsize()} URLs in the queue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d4b6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service process refused to terminate gracefully with SIGTERM, escalating to SIGKILL.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/50357691/miniforge3/envs/crawler/lib/python3.12/site-packages/selenium/webdriver/common/service.py\", line 179, in _terminate_process\n",
      "    self.process.wait(60)\n",
      "  File \"/Users/50357691/miniforge3/envs/crawler/lib/python3.12/subprocess.py\", line 1264, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/50357691/miniforge3/envs/crawler/lib/python3.12/subprocess.py\", line 2038, in _wait\n",
      "    raise TimeoutExpired(self.args, timeout)\n",
      "subprocess.TimeoutExpired: Command '['/Users/50357691/.wdm/drivers/chromedriver/mac64/140.0.7339.207/chromedriver-mac-arm64/chromedriver', '--port=49697']' timed out after 60 seconds\n"
     ]
    }
   ],
   "source": [
    "service = Service(ChromeDriverManager(driver_version=\"140\").install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7811ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookies 已载入\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.get(\"https://www.linkedin.com/\")\n",
    "load_cookies(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d39f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_url(url):\n",
    "    \n",
    "    try:\n",
    "        result = linkedin_common_crawler(url)\n",
    "        print(f\"Crawl Successfully: {url}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Crawl Failed: {url}, Error: {e}\")\n",
    "        return None\n",
    "\n",
    "futures = []\n",
    "while not url_queue.empty():\n",
    "    url = url_queue.get()\n",
    "    future = executor.submit(crawl_url, url)\n",
    "    futures.append(future)\n",
    "\n",
    "for future in futures:\n",
    "    data = future.result()\n",
    "    if data is not None:\n",
    "        results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "url_queue = queue.Queue()\n",
    "\n",
    "results = []\n",
    "results_lock = threading.Lock()\n",
    "\n",
    "def init_driver(cookies_file=\"cookies.pkl\"):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.linkedin.com\")  \n",
    "\n",
    "    # Load cookies if available\n",
    "    if load_cookies(driver, cookies_file):\n",
    "        driver.refresh()\n",
    "        time.sleep(3) \n",
    "    else:\n",
    "        print(\"no cookies found.\")\n",
    "        driver.get(\"https://www.linkedin.com/login\")\n",
    "        input(\"Please press Enter...\")\n",
    "        save_cookies(driver, cookies_file)\n",
    "        driver.refresh()\n",
    "        time.sleep(3)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def worker(worker_id, url_queue, cookies_file=\"cookies.pkl\"):\n",
    "    driver = init_driver(cookies_file)\n",
    "    while True:\n",
    "        try:\n",
    "            url = url_queue.get(timeout=5)\n",
    "        except queue.Empty:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            data = linkedin_common_crawler(driver, url)\n",
    "            if data:\n",
    "                with results_lock:\n",
    "                    results.append(data)\n",
    "                print(f\"[Worker {worker_id}] OK: {url}, got {len(data['jobs'])} jobs\")\n",
    "            else:\n",
    "                print(f\"[Worker {worker_id}] No data: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Worker {worker_id}] Error on {url}: {e}\")\n",
    "        finally:\n",
    "            url_queue.task_done()\n",
    "\n",
    "    driver.quit()\n",
    "    print(f\"[Worker {worker_id}] finished\")\n",
    "\n",
    "\n",
    "def run_crawler(urls, num_workers=3):\n",
    "    for url in urls:\n",
    "        url_queue.put(url)\n",
    "\n",
    "    threads = []\n",
    "    for i in range(num_workers):\n",
    "        t = threading.Thread(target=worker, args=(i, url_queue))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    url_queue.join()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbeb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_crawler(urls, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bcdb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    \"\"\"\n",
    "    Flatten LinkedIn job scraping results into a pandas DataFrame,\n",
    "    keeping the original search URL for each job.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for block in results:\n",
    "        search_url = block.get(\"url\")\n",
    "        for job in block.get(\"jobs\", []):\n",
    "            job_copy = job.copy()\n",
    "            job_copy[\"original_url\"] = search_url\n",
    "            rows.append(job_copy)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Show all columns, don’t drop any accidentally\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f777f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_metadata</th>\n",
       "      <th>job_url</th>\n",
       "      <th>original_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4092074034</td>\n",
       "      <td>Experienced Apprentice Electrician - Commercial</td>\n",
       "      <td>Weifield Group Contracting | A LOENBRO Company</td>\n",
       "      <td>Centennial, CO (On-site)</td>\n",
       "      <td>$23/hr - $29/hr · 401(k), Medical, Vision, +1 ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4092074034/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4150887505</td>\n",
       "      <td>2025 Summer Civil Engineer Assistant</td>\n",
       "      <td>BKF Engineers</td>\n",
       "      <td>Pleasanton, CA (On-site)</td>\n",
       "      <td>$20/hr - $31.47/hr</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4150887505/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4268452702</td>\n",
       "      <td>Engineer Intern Applicant - Engineer Intern 2</td>\n",
       "      <td>Louisiana Department Of Transportation and Dev...</td>\n",
       "      <td>Baton Rouge, LA (On-site)</td>\n",
       "      <td>$96.3K/yr</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4268452702/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4208295571</td>\n",
       "      <td>Engineering Intern - Secure Design</td>\n",
       "      <td>Walter P Moore</td>\n",
       "      <td>Washington, DC (On-site)</td>\n",
       "      <td>$25.30/hr - $35.20/hr</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4208295571/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4145060930</td>\n",
       "      <td>Praktikant (w/m/d)</td>\n",
       "      <td>Rödl &amp; Partner USA</td>\n",
       "      <td>Atlanta, GA (On-site)</td>\n",
       "      <td>$20/hr - $32/hr</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4145060930/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                         job_name  \\\n",
       "0  4092074034  Experienced Apprentice Electrician - Commercial   \n",
       "1  4150887505             2025 Summer Civil Engineer Assistant   \n",
       "2  4268452702    Engineer Intern Applicant - Engineer Intern 2   \n",
       "3  4208295571               Engineering Intern - Secure Design   \n",
       "4  4145060930                               Praktikant (w/m/d)   \n",
       "\n",
       "                                        company_name  \\\n",
       "0     Weifield Group Contracting | A LOENBRO Company   \n",
       "1                                      BKF Engineers   \n",
       "2  Louisiana Department Of Transportation and Dev...   \n",
       "3                                     Walter P Moore   \n",
       "4                                 Rödl & Partner USA   \n",
       "\n",
       "                job_location  \\\n",
       "0   Centennial, CO (On-site)   \n",
       "1   Pleasanton, CA (On-site)   \n",
       "2  Baton Rouge, LA (On-site)   \n",
       "3   Washington, DC (On-site)   \n",
       "4      Atlanta, GA (On-site)   \n",
       "\n",
       "                                        job_metadata  \\\n",
       "0  $23/hr - $29/hr · 401(k), Medical, Vision, +1 ...   \n",
       "1                                 $20/hr - $31.47/hr   \n",
       "2                                          $96.3K/yr   \n",
       "3                              $25.30/hr - $35.20/hr   \n",
       "4                                    $20/hr - $32/hr   \n",
       "\n",
       "                                             job_url  \\\n",
       "0  https://www.linkedin.com/jobs/view/4092074034/...   \n",
       "1  https://www.linkedin.com/jobs/view/4150887505/...   \n",
       "2  https://www.linkedin.com/jobs/view/4268452702/...   \n",
       "3  https://www.linkedin.com/jobs/view/4208295571/...   \n",
       "4  https://www.linkedin.com/jobs/view/4145060930/...   \n",
       "\n",
       "                                        original_url  \n",
       "0  https://www.linkedin.com/jobs/search/?keywords...  \n",
       "1  https://www.linkedin.com/jobs/search/?keywords...  \n",
       "2  https://www.linkedin.com/jobs/search/?keywords...  \n",
       "3  https://www.linkedin.com/jobs/search/?keywords...  \n",
       "4  https://www.linkedin.com/jobs/search/?keywords...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results_to_dataframe(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dd340ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"job_id\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b34739f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75c3fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Raw_linkedin_jobs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
