{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39966764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, random, json\n",
    "from html import unescape\n",
    "from crawler import linkedin_common_crawler, login_linkedin\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pickle\n",
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa9345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Raw_linkedin_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26436273",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: Can not connect to the Service /Users/50357691/.wdm/drivers/chromedriver/mac64/140.0.7339.207/chromedriver-mac-arm64/chromedriver\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWebDriverException\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m driver = \u001b[43mlogin_linkedin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LinkedIn-DataCenter-Jobs/crawler.py:44\u001b[39m, in \u001b[36mlogin_linkedin\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     42\u001b[39m USERNAME = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLINKEDIN_USERNAME\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m PASSWORD = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLINKEDIN_PASSWORD\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m driver = \u001b[43mwebdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mService\u001b[49m\u001b[43m(\u001b[49m\u001b[43mChromeDriverManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# login to LinkedIn login page\u001b[39;00m\n\u001b[32m     46\u001b[39m driver.get(\u001b[33m\"\u001b[39m\u001b[33mhttps://www.linkedin.com/login\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/crawler/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:47\u001b[39m, in \u001b[36mWebDriver.__init__\u001b[39m\u001b[34m(self, options, service, keep_alive)\u001b[39m\n\u001b[32m     44\u001b[39m service = service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[32m     45\u001b[39m options = options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrowserName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoog\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/crawler/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:58\u001b[39m, in \u001b[36mChromiumDriver.__init__\u001b[39m\u001b[34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[39m\n\u001b[32m     55\u001b[39m     options.browser_version = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.service.path = \u001b[38;5;28mself\u001b[39m.service.env_path() \u001b[38;5;129;01mor\u001b[39;00m finder.get_driver_path()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m executor = ChromiumRemoteConnection(\n\u001b[32m     61\u001b[39m     remote_server_addr=\u001b[38;5;28mself\u001b[39m.service.service_url,\n\u001b[32m     62\u001b[39m     browser_name=browser_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     ignore_proxy=options._ignore_local_proxy,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/crawler/lib/python3.12/site-packages/selenium/webdriver/common/service.py:115\u001b[39m, in \u001b[36mService.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m count += \u001b[32m1\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count == \u001b[32m70\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan not connect to the Service \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mWebDriverException\u001b[39m: Message: Can not connect to the Service /Users/50357691/.wdm/drivers/chromedriver/mac64/140.0.7339.207/chromedriver-mac-arm64/chromedriver\n"
     ]
    }
   ],
   "source": [
    "driver = login_linkedin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ed606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- optional cookie helpers ----------\n",
    "def save_cookies(driver, path=\"li_cookies.pkl\"):\n",
    "    pickle.dump(driver.get_cookies(), open(path, \"wb\"))\n",
    "    print(f\"Saved cookies → {path}\")\n",
    "\n",
    "def load_cookies(driver, path=\"li_cookies.pkl\"):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"No cookie file found.\"); return False\n",
    "    driver.get(\"https://www.linkedin.com/\")\n",
    "    for c in pickle.load(open(path, \"rb\")):\n",
    "        c.pop('sameSite', None)\n",
    "        try:\n",
    "            driver.add_cookie(c)\n",
    "        except Exception:\n",
    "            pass\n",
    "    driver.get(\"https://www.linkedin.com/feed/\")\n",
    "    time.sleep(2)\n",
    "    return True\n",
    "\n",
    "# ---------- parsing config ----------\n",
    "_HEADING_MAP = {\n",
    "    \"responsibilities\": \"Responsibilities\",\n",
    "    \"what you will do\": \"Responsibilities\",\n",
    "    \"what you'll do\": \"Responsibilities\",\n",
    "    \"what you do\": \"Responsibilities\",\n",
    "    \"duties\": \"Responsibilities\",\n",
    "    \"key duties\": \"Responsibilities\",\n",
    "    \"role & responsibilities\": \"Responsibilities\",\n",
    "    \"role and responsibilities\": \"Responsibilities\",\n",
    "    \"requirements\": \"Requirements\",\n",
    "    \"must have\": \"QualificationsRequired\",\n",
    "    \"you have\": \"QualificationsRequired\",\n",
    "    \"required qualifications\": \"QualificationsRequired\",\n",
    "    \"minimum qualifications\": \"QualificationsRequired\",\n",
    "    \"basic qualifications\": \"QualificationsRequired\",\n",
    "    \"qualifications\": \"QualificationsRequired\",\n",
    "    \"preferred qualifications\": \"QualificationsPreferred\",\n",
    "    \"preferred\": \"QualificationsPreferred\",\n",
    "    \"nice to have\": \"QualificationsPreferred\",\n",
    "    \"bonus\": \"QualificationsPreferred\",\n",
    "    \"plus\": \"QualificationsPreferred\",\n",
    "}\n",
    "_heading_regex = re.compile(r\"^\\s*(?:\" + r\"|\".join(re.escape(k) for k in sorted(_HEADING_MAP, key=len, reverse=True)) + r\")\\s*:?\\s*$\", re.IGNORECASE)\n",
    "_bullet_like = re.compile(r\"^\\s*[-–•●◦▪■☐✅▶︎»]+(?:\\s+|\\t)|^\\s*\\d+[\\.\\)]\\s+\")\n",
    "\n",
    "def _sleep(a=0.6, b=1.2): time.sleep(random.uniform(a,b))\n",
    "def _clean_text(t):\n",
    "    t = re.sub(r\"\\r\", \"\\n\", t); t = re.sub(r\"[ \\t]+\\n\", \"\\n\", t); t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip()\n",
    "def _normalize_bullets_block(text):\n",
    "    lines = [ln.strip() for ln in text.splitlines()]\n",
    "    out = []\n",
    "    for ln in lines:\n",
    "        if _bullet_like.search(ln):\n",
    "            ln = _bullet_like.sub(\"\", ln).strip()\n",
    "        out.append(ln)\n",
    "    return \"\\n\".join(out).strip()\n",
    "def wait(driver, t=15): return WebDriverWait(driver, t)\n",
    "def _scroll_into_view(driver, el):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", el)\n",
    "    _sleep(0.2,0.4)\n",
    "\n",
    "# ---------- expand \"About the job\" ----------\n",
    "def expand_about_section(driver):\n",
    "    sec = None\n",
    "    for xp in [\n",
    "        \"//section[.//h2[contains(translate(.,'ABOUTHEJOB','abouthejob'),'about the job')]]\",\n",
    "        \"//section[contains(@aria-label,'About the job') or contains(@class,'jobs-description')]\",\n",
    "        \"//div[contains(@class,'jobs-description')]//section\",\n",
    "    ]:\n",
    "        try:\n",
    "            sec = wait(driver, 12).until(EC.presence_of_element_located((By.XPATH, xp)))\n",
    "            _scroll_into_view(driver, sec); break\n",
    "        except TimeoutException: pass\n",
    "    containers = [sec] if sec else [driver.find_element(By.TAG_NAME,\"body\")]\n",
    "    clicked = 0\n",
    "    for root in containers:\n",
    "        for xp in [\n",
    "            \".//button[contains(., 'See more') or .//span[contains(.,'See more')]]\",\n",
    "            \".//a[contains(., 'See more') or .//span[contains(.,'See more')]]\",\n",
    "            \".//button[contains(@aria-expanded,'false') and (contains(.,'See more') or contains(@aria-label,'See more'))]\",\n",
    "        ]:\n",
    "            try:\n",
    "                for btn in root.find_elements(By.XPATH, xp):\n",
    "                    if not btn.is_displayed(): continue\n",
    "                    _scroll_into_view(driver, btn); _sleep(0.1,0.2)\n",
    "                    try: btn.click()\n",
    "                    except ElementClickInterceptedException: driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                    clicked += 1; _sleep(0.15,0.35)\n",
    "            except Exception: pass\n",
    "    print(f\"[expand] Clicked {clicked} 'See more' buttons.\" if clicked else \"[expand] No 'See more' buttons (maybe already expanded).\")\n",
    "\n",
    "# ---------- hidden JSON helpers ----------\n",
    "def _flatten_strings(x):\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return \"\\n\".join(_flatten_strings(i) for i in x if i is not None).strip()\n",
    "    return str(x) if x is not None else \"\"\n",
    "def _strip_html(html):\n",
    "    if not html: return \"\"\n",
    "    html = unescape(html)\n",
    "    html = re.sub(r\"<\\s*br\\s*/?>\", \"\\n\", html, flags=re.I)\n",
    "    html = re.sub(r\"</\\s*p\\s*>\", \"\\n\\n\", html, flags=re.I)\n",
    "    html = re.sub(r\"<[^>]+>\", \"\", html)\n",
    "    html = re.sub(r\"\\n{3,}\", \"\\n\\n\", html)\n",
    "    return html.strip()\n",
    "def _walk_find(obj, keys=(\"formattedDescription\",\"description\",\"plainDescription\")):\n",
    "    if isinstance(obj, dict):\n",
    "        for k in keys:\n",
    "            if k in obj and obj[k]: return obj[k]\n",
    "        for v in obj.values():\n",
    "            got = _walk_find(v, keys)\n",
    "            if got: return got\n",
    "    elif isinstance(obj, list):\n",
    "        for v in obj:\n",
    "            got = _walk_find(v, keys)\n",
    "            if got: return got\n",
    "    return None\n",
    "\n",
    "# ---------- extraction (DOM → bpr-guid → JSON-LD → body text) ----------\n",
    "def extract_about_text(driver):\n",
    "    # extra time for hydration\n",
    "    try:\n",
    "        wait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main#main, body\")))\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "    # 1) Visible DOM\n",
    "    selectors = [\n",
    "        (By.CSS_SELECTOR, \"section[aria-label*='About the job'] .show-more-less-html__markup\"),\n",
    "        (By.CSS_SELECTOR, \"section[aria-label*='About the job'] [data-test-description]\"),\n",
    "        (By.CSS_SELECTOR, \"section[aria-label*='About the job'] .jobs-description__content\"),\n",
    "        (By.CSS_SELECTOR, \"section[aria-label*='About the job'] .jobs-description__container\"),\n",
    "        (By.CSS_SELECTOR, \"div.show-more-less-html__markup\"),\n",
    "        (By.CSS_SELECTOR, \".jobs-description__content .show-more-less-html__markup\"),\n",
    "        (By.XPATH, \"//section[.//h2[contains(translate(.,'ABOUTHEJOB','abouthejob'),'about the job')]]//*[self::div or self::article][string-length(normalize-space())>0]\"),\n",
    "    ]\n",
    "    for by, sel in selectors:\n",
    "        try:\n",
    "            el = wait(driver, 10).until(EC.presence_of_element_located((by, sel)))\n",
    "            _scroll_into_view(driver, el)\n",
    "            txt = (el.get_attribute(\"innerText\") or el.text or \"\").strip()\n",
    "            if txt:\n",
    "                print(f\"[extract] DOM matched {by} {sel}\")\n",
    "                return _clean_text(txt)\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    # 2) <code id=\"bpr-guid-...\"> JSON\n",
    "    try:\n",
    "        codes = driver.find_elements(By.CSS_SELECTOR, \"code[id^='bpr-guid-']\")\n",
    "        for c in codes:\n",
    "            raw = (c.get_attribute(\"innerHTML\") or \"\").strip()\n",
    "            if not raw or raw[0] not in \"{[}\": continue\n",
    "            if (\"description\" not in raw) and (\"jobPosting\" not in raw) and (\"decoratedJobPosting\" not in raw): continue\n",
    "            try: data = json.loads(raw)\n",
    "            except Exception: continue\n",
    "            html_block = _walk_find(data, keys=(\"formattedDescription\",\"description\",\"plainDescription\"))\n",
    "            if html_block:\n",
    "                print(\"[extract] Using JSON fallback (bpr-guid).\")\n",
    "                return _clean_text(_strip_html(_flatten_strings(html_block)))\n",
    "    except Exception as e:\n",
    "        print(f\"[extract] JSON bpr error: {e}\")\n",
    "\n",
    "    # 3) <script type=\"application/ld+json\"> JSON-LD\n",
    "    try:\n",
    "        scripts = driver.find_elements(By.CSS_SELECTOR, \"script[type='application/ld+json']\")\n",
    "        for s in scripts:\n",
    "            raw = (s.get_attribute(\"innerHTML\") or \"\").strip()\n",
    "            if not raw or '\"description\"' not in raw: continue\n",
    "            try:\n",
    "                data = json.loads(raw)\n",
    "            except Exception:\n",
    "                continue\n",
    "            def _ld_desc(d):\n",
    "                return d.get(\"description\") if isinstance(d, dict) else None\n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    desc = _ld_desc(item)\n",
    "                    if desc:\n",
    "                        print(\"[extract] Using JSON-LD fallback (list).\")\n",
    "                        return _clean_text(_strip_html(desc))\n",
    "            else:\n",
    "                desc = _ld_desc(data)\n",
    "                if desc:\n",
    "                    print(\"[extract] Using JSON-LD fallback (dict).\")\n",
    "                    return _clean_text(_strip_html(desc))\n",
    "    except Exception as e:\n",
    "        print(f\"[extract] JSON-LD error: {e}\")\n",
    "\n",
    "    # 4) body-text slice\n",
    "    body_text = (driver.execute_script(\"return document.body.innerText\") or \"\").strip()\n",
    "    if body_text:\n",
    "        t = re.sub(r\"[ \\t]+\", \" \", body_text); t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "        m = re.search(r\"(about the job)\\s*[:：]?\\s*(.+)\", t, flags=re.I|re.S)\n",
    "        if m:\n",
    "            after = m.group(2)\n",
    "            stops = [r\"\\n\\s*benefits\\b\", r\"\\n\\s*pay\\s+or\\s+salary\\b\", r\"\\n\\s*posted by\\b\",\n",
    "                     r\"\\n\\s*seniority level\\b\", r\"\\n\\s*job function\\b\", r\"\\n\\s*industr(y|ies)\\b\",\n",
    "                     r\"\\n\\s*skills\\b\", r\"\\n\\s*company overview\\b\", r\"\\n\\s*more about\\b\"]\n",
    "            stop_m = re.compile(\"|\".join(stops), flags=re.I).search(after)\n",
    "            about = (after[:stop_m.start()] if stop_m else after).strip()\n",
    "            print(\"[extract] Using body-text fallback slice.\")\n",
    "            return _clean_text(about)\n",
    "\n",
    "    print(\"[extract] No content found.\"); return \"\"\n",
    "\n",
    "# ---------- parsing → 5 columns ----------\n",
    "def split_into_sections(full_text):\n",
    "    full_text = re.sub(r\"^\\s*about the job\\s*:\\s*\", \"\", full_text, flags=re.I).strip()\n",
    "    full_text = _normalize_bullets_block(_clean_text(full_text))\n",
    "    sections, buf, current_key = [], [], \"Description\"\n",
    "    for raw_line in full_text.splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if _heading_regex.match(line):\n",
    "            if buf: sections.append((current_key, \"\\n\".join(buf).strip())); buf=[]\n",
    "            current_key = _HEADING_MAP[line.lower()]\n",
    "        else:\n",
    "            buf.append(raw_line)\n",
    "    if buf: sections.append((current_key, \"\\n\".join(buf).strip()))\n",
    "    if not any(k != \"Description\" for k,_ in sections):\n",
    "        return {\"Description\": full_text, \"Responsibilities\":\"\", \"QualificationsRequired\":\"\", \"QualificationsPreferred\":\"\", \"Requirements\":\"\"}\n",
    "    out = {k:\"\" for k in [\"Description\",\"Responsibilities\",\"QualificationsRequired\",\"QualificationsPreferred\",\"Requirements\"]}\n",
    "    for k,v in sections:\n",
    "        v=v.strip()\n",
    "        if not v: continue\n",
    "        if k==\"QualificationsRequired\" and re.search(r\"\\b(preferred|nice to have|bonus|plus)\\b\", v, flags=re.I):\n",
    "            k=\"QualificationsPreferred\"\n",
    "        out[k] = (out[k] + (\"\\n\\n\" if out[k] else \"\") + v).strip()\n",
    "    return out\n",
    "\n",
    "def parse_about_to_columns(about_text):\n",
    "    parsed = split_into_sections(about_text)\n",
    "    for k in [\"Description\",\"Responsibilities\",\"QualificationsRequired\",\"QualificationsPreferred\",\"Requirements\"]:\n",
    "        parsed.setdefault(k,\"\")\n",
    "    return parsed\n",
    "\n",
    "# ---------- public API ----------\n",
    "def load_job_and_get_about(driver, url, timeout=25):\n",
    "    driver.get(url)\n",
    "    try: wait(driver, timeout).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main#main, body\")))\n",
    "    except TimeoutException: print(\"[warn] main/body not detected in time; continuing.\")\n",
    "    _sleep(0.8,1.6); expand_about_section(driver)\n",
    "    return extract_about_text(driver)\n",
    "\n",
    "def enrich_with_about_columns(driver, df, url_col=\"job_url\", max_urls=None):\n",
    "    assert url_col in df.columns, f\"Column '{url_col}' not in df. Columns: {df.columns.tolist()}\"\n",
    "    df_in = df[df[url_col].astype(str).str.startswith(\"http\")].copy()\n",
    "    if max_urls is not None: df_in = df_in.iloc[:max_urls].copy()\n",
    "    rows = []\n",
    "    for i, url in enumerate(df_in[url_col].tolist(), 1):\n",
    "        print(f\"\\n[{i}/{len(df_in)}] {url}\")\n",
    "        try:\n",
    "            about = load_job_and_get_about(driver, url)\n",
    "            cols = parse_about_to_columns(about)\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {e.__class__.__name__}: {e}\")\n",
    "            cols = {\"Description\":\"\",\"Responsibilities\":\"\",\"QualificationsRequired\":\"\",\"QualificationsPreferred\":\"\",\"Requirements\":\"\"}\n",
    "        rows.append({url_col: url, **cols})\n",
    "        _sleep(0.8,1.4)\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    merged = df.merge(out_df, on=url_col, how=\"left\")\n",
    "    for k in [\"Description\",\"Responsibilities\",\"QualificationsRequired\",\"QualificationsPreferred\",\"Requirements\"]:\n",
    "        if k not in merged.columns: merged[k] = \"\"\n",
    "    return merged\n",
    "\n",
    "def debug_one(driver, url):\n",
    "    print(\"URL:\", url)\n",
    "    driver.get(url)\n",
    "    try: WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"main#main, body\")))\n",
    "    except TimeoutException: print(\"[debug] main/body did not appear; continuing.\")\n",
    "    time.sleep(1.0); expand_about_section(driver)\n",
    "    about = extract_about_text(driver)\n",
    "    print(\"\\n---- ABOUT (first 600 chars) ----\\n\", (about or \"\")[:600])\n",
    "    return about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4047f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/2] https://www.linkedin.com/jobs/view/4092074034/?eBP=CwEAAAGZhxZCI9vwBpBI6eId1Zx3Mf1JuIGWmnJtjEnsoAv9T0iE-htd73q_t3lftPPZfTYGC77a3gd-El5lFq0fQe5-YQRZYOEye0d9j9YoYnNmAqtZaQVFwBJnInY4rCW0w_T_GGlzvXzvIJPRiysjjagNKVTadpohwooei1qs1dROGU4GrpafBr73-HM4txURoUM1FmtAjmnkSTtnTNtH0sA3j4Mr4yV537kSf6owb6lMUjH3_d8RP75_gigJw_ZJeFzlbPdNrg3L2nQxcYG4KMOksHtPqlAvh1_xHdGuRJtHpgn5RL5eBdJAWDLN-9HDwfGLR5BT2BiAFmH2peHSiPC8-ZKtkXqpmSqlJ1q1CuaXyaVDIrIoQH3acaDssAH_dudZK-lQQdo9y3Y15FH2_kLNLgsh7jixxrgZOxBp4CcKgak97sKHBpB-dIBQ7_1na97mJzguUqIkkabdacPYmOCQFnPYaC3ujBsc-DBlfngM_gftr6r7uvzt_a7tI_PFKQA&refId=AFK0i5jcJKRfsl58VjGnCQ%3D%3D&trackingId=UbrP4fMEOUvYe1oeK2HrzQ%3D%3D&trk=flagship3_search_srp_jobs\n",
      "[expand] No 'See more' buttons (maybe already expanded).\n",
      "[extract] DOM matched css selector div.show-more-less-html__markup\n",
      "\n",
      "[2/2] https://www.linkedin.com/jobs/view/4150887505/?eBP=CwEAAAGZhxZCI2hKoJCF4gOaMS9-HIpIFrV5_aYaZvE4Jn79WmAMtMTp9xIFLCeMZRLT6IrO9xpGav6VuH3ZQIwheDhImSPJEny9puU3iShGo6oddcgbZxpeGaYI8dRzYGuo2RetSRxb68mfCl7Q55u7IVbEcwKkj44un2nX8l-W34EmPS13w3aePHX_SF_7oeF9QtHDRUx9YVtpn-SNcKsdUN4un8_GhXj5AheyUATUcfVZZgNlBdW1utAOdW70y6hSIsu7TdUMZ5S49RTBftDCKvkM871uxyd30sFDt4N3K8WGr-6RGzsB_zDJOlOn-HXk5YpiNvO_2FnZmUnTZB1y8rDzaukH7rGZlHQax22kPNrfvJwv5CDQI-8EkwWW9ED7dyMvTNIoPfez3jLEnlBySmNvbhhWGx0w3TDbvz9KjjyLaWDAVHhK6KUcYxQkT9YUsVxLo1ryI1dLHcOW4Za0THbQEna9Ju4ddgtotYs_x6MY9Wu9GkGVO546DR7ojhFH&refId=AFK0i5jcJKRfsl58VjGnCQ%3D%3D&trackingId=krkIemetRsSqmW5A1Y4bPw%3D%3D&trk=flagship3_search_srp_jobs\n",
      "[expand] No 'See more' buttons (maybe already expanded).\n",
      "[extract] DOM matched css selector div.show-more-less-html__markup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_metadata</th>\n",
       "      <th>job_url</th>\n",
       "      <th>original_url</th>\n",
       "      <th>Description</th>\n",
       "      <th>Responsibilities</th>\n",
       "      <th>QualificationsRequired</th>\n",
       "      <th>QualificationsPreferred</th>\n",
       "      <th>Requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.092074e+09</td>\n",
       "      <td>Experienced Apprentice Electrician - Commercial</td>\n",
       "      <td>Weifield Group Contracting | A LOENBRO Company</td>\n",
       "      <td>Centennial, CO (On-site)</td>\n",
       "      <td>$23/hr - $29/hr · 401(k), Medical, Vision, +1 ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4092074034/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "      <td>Brief Description\\n\\n*This posting is for Expe...</td>\n",
       "      <td>While continuing your education in the evening...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.150888e+09</td>\n",
       "      <td>2025 Summer Civil Engineer Assistant</td>\n",
       "      <td>BKF Engineers</td>\n",
       "      <td>Pleasanton, CA (On-site)</td>\n",
       "      <td>$20/hr - $31.47/hr</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4150887505/...</td>\n",
       "      <td>https://www.linkedin.com/jobs/search/?keywords...</td>\n",
       "      <td>Are you a passionate civil engineering student...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Currently enrolled in B.S. Civil Engineering o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job_id                                         job_name  \\\n",
       "0  4.092074e+09  Experienced Apprentice Electrician - Commercial   \n",
       "1  4.150888e+09             2025 Summer Civil Engineer Assistant   \n",
       "\n",
       "                                     company_name              job_location  \\\n",
       "0  Weifield Group Contracting | A LOENBRO Company  Centennial, CO (On-site)   \n",
       "1                                   BKF Engineers  Pleasanton, CA (On-site)   \n",
       "\n",
       "                                        job_metadata  \\\n",
       "0  $23/hr - $29/hr · 401(k), Medical, Vision, +1 ...   \n",
       "1                                 $20/hr - $31.47/hr   \n",
       "\n",
       "                                             job_url  \\\n",
       "0  https://www.linkedin.com/jobs/view/4092074034/...   \n",
       "1  https://www.linkedin.com/jobs/view/4150887505/...   \n",
       "\n",
       "                                        original_url  \\\n",
       "0  https://www.linkedin.com/jobs/search/?keywords...   \n",
       "1  https://www.linkedin.com/jobs/search/?keywords...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Brief Description\\n\\n*This posting is for Expe...   \n",
       "1  Are you a passionate civil engineering student...   \n",
       "\n",
       "                                    Responsibilities QualificationsRequired  \\\n",
       "0  While continuing your education in the evening...                          \n",
       "1                                                                             \n",
       "\n",
       "  QualificationsPreferred                                       Requirements  \n",
       "0                                                                             \n",
       "1                          Currently enrolled in B.S. Civil Engineering o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.head(2)\n",
    "test_df = enrich_with_about_columns(driver, test_df, url_col= 'job_url')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6bc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845f9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a3b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
