{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d387d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f6b16",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ef864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"detailed_job_infos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382468d4",
   "metadata": {},
   "source": [
    "### Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a812f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_description(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Step 1: Replace problematic unicode spaces\n",
    "    text = text.replace('\\u202f', ' ')   # Narrow no-break space\n",
    "    text = text.replace('\\xa0', ' ')     # Non-breaking space\n",
    "    text = text.replace('\\r', '')        # Carriage return\n",
    "\n",
    "    # Step 2: Collapse multiple newlines to 2 (for paragraphs)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "\n",
    "    # Step 3: Remove line breaks that split sentences or phrases\n",
    "    text = re.sub(r'(?<=[a-z0-9])\\n(?=[a-z0-9])', ' ', text)\n",
    "    text = re.sub(r'(?<=[A-Za-z0-9])\\n(?=[A-Za-z0-9])', ' ', text)\n",
    "\n",
    "    # Step 4: Standardize double newlines (if you want real paragraphs)\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)   # Keep \\n\\n as paragraph separator\n",
    "\n",
    "    # Step 5: Replace remaining single \\n with space (not paragraphs)\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # Step 6: Normalize spacing\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c9c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job_description\"] = df[\"job_description\"].apply(clean_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487c2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_job_description_meta(df, meta_column=\"job_description_meta\"):\n",
    "    \"\"\"\n",
    "    Parse and expand a stringified dict column (like 'job_description_meta') into new columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a column of stringified dicts.\n",
    "        meta_column (str): Column name containing stringified dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with new columns extracted from the dict.\n",
    "    \"\"\"\n",
    "    def safe_parse(s):\n",
    "        try:\n",
    "            return ast.literal_eval(s) if isinstance(s, str) else {}\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    # Parse and expand\n",
    "    meta_parsed = df[meta_column].apply(safe_parse)\n",
    "    meta_df = pd.DataFrame(meta_parsed.tolist())\n",
    "\n",
    "    # Merge and return\n",
    "    df_expanded = pd.concat([df, meta_df], axis=1)\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6483cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expand_job_description_meta(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aecedb",
   "metadata": {},
   "source": [
    "### Location and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf897f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "add = pd.read_csv(\"additional_infos.csv\")\n",
    "additional_info = add[['job_url', 'workplace_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fc4453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, additional_info, on=\"job_url\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "905d85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(location):\n",
    "    if pd.isna(location):\n",
    "        return \"Unknown\"\n",
    "    if \"United States\" in location:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Match \", XX\" where XX is 2 uppercase letters (state abbreviation)\n",
    "    match = re.search(r\",\\s*([A-Z]{2})$\", location.strip())\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Apply to the merged DataFrame\n",
    "df_merged[\"State\"] = df_merged[\"company_location\"].apply(extract_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89f306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop([\"company_location\", \"job_description_meta\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e898e",
   "metadata": {},
   "source": [
    "### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d361b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_salary(s):\n",
    "    \"\"\"\n",
    "    Parse salary string into an estimated annual salary (numeric).\n",
    "    Handles hourly, weekly, monthly, yearly, and ranges.\n",
    "    Assumptions:\n",
    "    - Hourly: 40 hrs/week, 52 weeks/year\n",
    "    - Weekly: 52 weeks/year\n",
    "    - Monthly: 12 months/year\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return np.nan\n",
    "    \n",
    "    s = s.lower().replace(\",\", \"\").strip()\n",
    "\n",
    "    # Extract numbers (with optional K or M)\n",
    "    nums = re.findall(r\"\\$?\\d+(?:\\.\\d+)?[kKmM]?\", s)\n",
    "    if not nums:\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert numbers into floats\n",
    "    values = []\n",
    "    for n in nums:\n",
    "        n = n.replace(\"$\", \"\")\n",
    "        if \"k\" in n:\n",
    "            values.append(float(n[:-1]) * 1000)\n",
    "        elif \"m\" in n:\n",
    "            values.append(float(n[:-1]) * 1_000_000)\n",
    "        else:\n",
    "            values.append(float(n))\n",
    "    \n",
    "    # If it's a range, take the average\n",
    "    val = sum(values) / len(values)\n",
    "\n",
    "    # Detect time unit\n",
    "    if re.search(r\"/?\\s*hour|/hr\", s):\n",
    "        val *= 40 * 52\n",
    "    elif re.search(r\"/?\\s*week|/wk\", s):\n",
    "        val *= 52\n",
    "    elif re.search(r\"/?\\s*month|/mo\", s):\n",
    "        val *= 12\n",
    "    elif re.search(r\"/?\\s*year|/yr|/y\", s):\n",
    "        pass  # already annual\n",
    "    else:\n",
    "        # No explicit unit â†’ assume yearly\n",
    "        pass\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84dd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"salary_range\"] = df[\"salary_range\"].apply(parse_salary)\n",
    "df_merged.rename(columns={\"salary_range\": \"Salary ($)\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3a125",
   "metadata": {},
   "source": [
    "### Publish Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "111ab66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_relative_to_date(df, col_name=\"publish_time\", new_col=\"publish_date\"):\n",
    "    def parse_relative_time(text):\n",
    "        # Skip NaN or non-string\n",
    "        if not isinstance(text, str):\n",
    "            return None\n",
    "\n",
    "        text = text.lower().strip()\n",
    "        today = datetime.today()\n",
    "\n",
    "        match = re.match(r\"(\\d+)\\s+(day|week|month|year)s?\\s+ago\", text)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        value, unit = int(match.group(1)), match.group(2)\n",
    "\n",
    "        if unit == \"day\":\n",
    "            delta = timedelta(days=value)\n",
    "        elif unit == \"week\":\n",
    "            delta = timedelta(weeks=value)\n",
    "        elif unit == \"month\":\n",
    "            delta = timedelta(days=30 * value)\n",
    "        elif unit == \"year\":\n",
    "            delta = timedelta(days=365 * value)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        return (today - delta).strftime(\"%m/%d/%y\")  # Format as MM/DD/YY\n",
    "\n",
    "    df[new_col] = df[col_name].apply(parse_relative_time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551f04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = convert_relative_to_date(df_merged)\n",
    "df_merged.drop([\"publish_time\"], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "803218f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"../linkedin_data_center_jobs.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonskill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
